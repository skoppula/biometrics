{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load classify_nnet.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# all utterance data [utt1 mfcc frames [N1 x 60], utt2 frames]\n",
    "def mkdir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# assumes inputs in y from 0 ... n\n",
    "def one_hot_encode(y, num_spks):\n",
    "    num_frames = np.shape(y)[0]\n",
    "    one_hot_lbls = np.zeros((num_frames, num_spks))\n",
    "    one_hot_lbls[np.arange(num_frames), y] = 1\n",
    "    return one_hot_lbls\n",
    "\n",
    "def get_class_net(model_path, n_inp_frms, num_spks):\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "    from keras.layers.advanced_activations import LeakyReLU\n",
    "    from keras.utils.visualize_util import plot\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    # Add batch normalization: keras.layers.normalization.BatchNormalization()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(n_inp_frms*60,))) # 60 MFCCs / frame\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_spks))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    plot(model, to_file=model_path + 'architecture.png')\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy', 'precision', 'recall'])\n",
    "    return model\n",
    "\n",
    "def train_network(model, tr_x, tr_y, model_path, n_epochs=250, batch_size=50):\n",
    "\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "    saved_model_path = model_path + \"curr_best_weights.hdf5\"\n",
    "    ckpt = ModelCheckpoint(saved_model_path, monitor='val_acc', verbose=0, save_best_only=False, mode='max')\n",
    "    # early_stop = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
    "    trn_history = model.fit(tr_x, tr_y, validation_split=0.1, shuffle=True,\n",
    "                        batch_size=batch_size, nb_epoch=n_epochs, verbose=1,\n",
    "                        callbacks=[ckpt])\n",
    "\n",
    "    np.save(model_path + \"history.npy\", trn_history.history)\n",
    "\n",
    "def remap_spk_ids(enr_y, ver_y):\n",
    "    # REMAP SPEAKER IDs TO 0..n\n",
    "    spk_mappings = {}\n",
    "    curr_map = 0\n",
    "    all_spks = set(enr_y).union(set(ver_y))\n",
    "    for spk in all_spks:\n",
    "        if spk not in spk_mappings:\n",
    "            spk_mappings[spk] = curr_map\n",
    "            curr_map += 1\n",
    "    map_spks = np.vectorize(lambda x: spk_mappings[x])\n",
    "    print(\"Speaker Re-mappings:\", spk_mappings)\n",
    "    return all_spks, map_spks(enr_y), map_spks(ver_y), spk_mappings\n",
    "\n",
    "def read_data(path, n_inp_frms):\n",
    "    x = np.load(path + \"X.npy\")\n",
    "    n_frames = np.shape(x)[0]\n",
    "    x = x.reshape(n_frames, N_INP_FRMS * 60) # 60 MFCCs per frame\n",
    "    y = np.load(path + \"y.npy\")\n",
    "    assert n_frames == np.shape(y)[0]\n",
    "    return x, y\n",
    "\n",
    "def get_params():\n",
    "    N_INP_FRMS = 120\n",
    "    BASE_PATH = \"/home/skoppula/biometrics/data/yoho/kaldi_yoho/data/\"\n",
    "    MODEL_PATH = 'classify_model_' + str(N_INP_FRMS) + '/'\n",
    "    mkdir(MODEL_PATH)\n",
    "    VER_PATH = BASE_PATH + \"verify/final/nn_inp-\" + str(N_INP_FRMS) + \"_frames/\"\n",
    "    ENR_PATH = BASE_PATH + \"enroll/final/nn_inp-\" + str(N_INP_FRMS) + \"_frames/\"\n",
    "\n",
    "    return N_INP_FRMS, BASE_PATH, MODEL_PATH, VER_PATH, ENR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dataset_shuffle(X, y):\n",
    "    num_els = np.shape(X)[0]\n",
    "    assert num_els == np.shape(y)[0]\n",
    "    idxs = np.random.permutation(np.arange(num_els))\n",
    "    return X[idxs], y[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMS:  (120, '/home/skoppula/biometrics/data/yoho/kaldi_yoho/data/', 'classify_model_120/', '/home/skoppula/biometrics/data/yoho/kaldi_yoho/data/verify/final/nn_inp-120_frames/', '/home/skoppula/biometrics/data/yoho/kaldi_yoho/data/enroll/final/nn_inp-120_frames/')\n",
      "Enroll X shape (13685, 7200)\n",
      "Enroll y shape (13685,)\n",
      "Verify y shape (4488,)\n",
      "Speaker Re-mappings: {261: 134, 268: 135, 271: 136, 277: 137, 101: 0, 102: 1, 103: 2, 104: 3, 105: 4, 106: 5, 107: 6, 108: 7, 109: 8, 110: 9, 111: 10, 112: 11, 113: 12, 114: 13, 115: 14, 116: 15, 117: 16, 118: 17, 119: 18, 120: 19, 121: 20, 122: 21, 124: 22, 125: 23, 126: 24, 127: 25, 128: 26, 130: 27, 131: 28, 132: 29, 133: 30, 134: 31, 135: 32, 136: 33, 137: 34, 138: 35, 139: 36, 140: 37, 141: 38, 142: 39, 143: 40, 144: 41, 145: 42, 146: 43, 147: 44, 148: 45, 150: 46, 151: 47, 152: 48, 154: 49, 155: 50, 156: 51, 157: 52, 158: 53, 159: 54, 160: 55, 161: 56, 162: 57, 163: 58, 164: 59, 165: 60, 166: 61, 167: 62, 168: 63, 169: 64, 170: 65, 171: 66, 172: 67, 174: 68, 175: 69, 176: 70, 178: 71, 180: 72, 181: 73, 182: 74, 183: 75, 184: 76, 185: 77, 188: 78, 189: 79, 190: 80, 191: 81, 192: 82, 193: 83, 196: 84, 197: 85, 198: 86, 199: 87, 200: 88, 201: 89, 202: 90, 203: 91, 204: 92, 205: 93, 206: 94, 207: 95, 208: 96, 209: 97, 210: 98, 211: 99, 212: 100, 213: 101, 215: 102, 216: 103, 218: 104, 219: 105, 220: 106, 221: 107, 222: 108, 223: 109, 224: 110, 225: 111, 226: 112, 227: 113, 228: 114, 229: 115, 230: 116, 231: 117, 232: 118, 233: 119, 234: 120, 235: 121, 236: 122, 237: 123, 238: 124, 239: 125, 240: 126, 241: 127, 242: 128, 243: 129, 244: 130, 245: 131, 246: 132, 247: 133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17) # reproducibility\n",
    "\n",
    "params = get_params()\n",
    "N_INP_FRMS, BASE_PATH, MODEL_PATH, VER_PATH, ENR_PATH = params\n",
    "print(\"PARAMS: \", params)\n",
    "\n",
    "enr_x, enr_y = read_data(ENR_PATH, N_INP_FRMS)\n",
    "_, ver_y = read_data(VER_PATH, N_INP_FRMS)\n",
    "del _\n",
    "\n",
    "print(\"Enroll X shape\", np.shape(enr_x))\n",
    "print(\"Enroll y shape\", np.shape(enr_y))\n",
    "print(\"Verify y shape\", np.shape(ver_y))\n",
    "\n",
    "all_spks, enr_y, _, _ = remap_spk_ids(enr_y, ver_y)\n",
    "model = get_class_net(MODEL_PATH, N_INP_FRMS, len(all_spks))\n",
    "\n",
    "enr_y = one_hot_encode(enr_y, len(all_spks))\n",
    "print(\"One-Hot Enroll (y) shape\", np.shape(enr_y))\n",
    "del ver_y, all_spks\n",
    "\n",
    "train_network(model, enr_x, enr_y, MODEL_PATH)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

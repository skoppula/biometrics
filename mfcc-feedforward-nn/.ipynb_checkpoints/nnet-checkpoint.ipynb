{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(s) Path:  model_120/\n",
      "Using verification path:  /home/skoppula/biometrics/data/yoho/kaldi_yoho/data/verify/final/nn_inp-120_frames/\n",
      "Using enroll data path:  /home/skoppula/biometrics/data/yoho/kaldi_yoho/data/enroll/final/nn_inp-120_frames/\n",
      "Enroll X shape (13685, 7200)\n",
      "Enroll y shape (13685,)\n",
      "Verify X shape (4488, 7200)\n",
      "Verify y shape (4488,)\n",
      "Evaluating and training for current speaker:  109\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_29 (Dense)                 (None, 64)            460864      dense_input_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 64)            0           dense_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 64)            0           activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 64)            4160        dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 64)            0           dense_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 64)            0           activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 16)            1040        dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 16)            0           dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 2)             34          activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 2)             0           dense_32[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 466,098\n",
      "Trainable params: 466,098\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 10948 samples, validate on 2737 samples\n",
      "Epoch 1/2\n",
      "10900/10948 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9890 - precision: 0.9888 - recall: 0.9890Epoch 00000: saving model to model_120/109/109_curr_best_weights.hdf5\n",
      "10948/10948 [==============================] - 6s - loss: 0.1558 - acc: 0.9889 - precision: 0.9888 - recall: 0.9889 - val_loss: 9.5139e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/2\n",
      "10900/10948 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9912 - precision: 0.9912 - recall: 0.9912Epoch 00001: saving model to model_120/109/109_curr_best_weights.hdf5\n",
      "10948/10948 [==============================] - 5s - loss: 0.1421 - acc: 0.9912 - precision: 0.9912 - recall: 0.9912 - val_loss: 1.1805e-04 - val_acc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Test score: 0.144126126698\n",
      "Test accuracy: 0.990864527629\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# all utterance data [utt1 mfcc frames [N1 x 60], utt2 frames]\n",
    "def mkdir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_verify_lbls(y, curr_spk):\n",
    "    return np.array(list(map(lambda x: 1 if x == curr_spk else 0, y)))\n",
    "\n",
    "def conv_to_ver_and_one_hot_encode(y, spk):\n",
    "    # convert to verification task\n",
    "    ver_lbls = get_verify_lbls(y, curr_spk)\n",
    "    num_frames = np.shape(y)[0]\n",
    "\n",
    "    one_hot_lbls = np.zeros((num_frames, 2))\n",
    "    one_hot_lbls[np.arange(num_frames), ver_lbls] = 1\n",
    "    return one_hot_lbls\n",
    "\n",
    "def get_ver_network_arch(model_path):\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "    from keras.utils.visualize_util import plot\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    # Add batch normalization: keras.layers.normalization.BatchNormalization()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(N_INP_FRMS*60,))) # 60 MFCCs / frame\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    plot(model, to_file=model_path + 'architecture.png')\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy', 'precision', 'recall'])\n",
    "    return model\n",
    "\n",
    "def evaluate_activations(model, X, layer):\n",
    "    from keras.layers.core import K\n",
    "    get_layer_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output])\n",
    "    return get_layer_output([X, 0])[0]\n",
    "\n",
    "def train_and_test_network(model, tr_x, tr_y, te_x, te_y, curr_spk, model_path, n_epochs=75, batch_size=50):\n",
    "\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    import gc\n",
    "\n",
    "    saved_model_path = model_path + \"_curr_best_weights_\"  + str(curr_spk) + \".hdf5\"\n",
    "    ckpt = ModelCheckpoint(saved_model_path, monitor='val_acc', verbose=0, save_best_only=False, mode='max')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
    "    trn_history = model.fit(tr_x, tr_y, validation_split=0.2,\n",
    "                        batch_size=batch_size, nb_epoch=n_epochs, verbose=1,\n",
    "                        callbacks=[ckpt, early_stop])\n",
    "\n",
    "    np.save(model_path + \"history_\" + str(curr_spk) + \".npy\", trn_history.history)\n",
    "\n",
    "    model.load_weights(saved_model_path)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "    # del tr_x, tr_y, val_x, val_y # for saving memory\n",
    "    score = model.evaluate(te_x, te_y, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    gc.collect() # fix suggested by https://github.com/tensorflow/tensorflow/issues/3388\n",
    "\n",
    "    model.load_weights(saved_model_path)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "    activations = evaluate_activations(model, te_x, 2)\n",
    "    np.save(model_path + \"activations_\" + str(curr_spk) + \".npy\", activations)\n",
    "\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(1337) # reproducibility\n",
    "\n",
    "    N_INP_FRMS = 120\n",
    "    MODEL_PATH = 'model_' + str(N_INP_FRMS) + '/'\n",
    "    mkdir(MODEL_PATH)\n",
    "    BASE_PATH = \"/home/skoppula/biometrics/data/yoho/kaldi_yoho/data/\"\n",
    "    VER_PATH = BASE_PATH + \"verify/final/nn_inp-\" + str(N_INP_FRMS) + \"_frames/\"\n",
    "    ENR_PATH = BASE_PATH + \"enroll/final/nn_inp-\" + str(N_INP_FRMS) + \"_frames/\"\n",
    "\n",
    "    print(\"Model(s) Path: \", MODEL_PATH)\n",
    "    print(\"Using verification path: \", VER_PATH)\n",
    "    print(\"Using enroll data path: \", ENR_PATH)\n",
    "\n",
    "    # ENROLL DATA LOAD\n",
    "    enr_x = np.load(ENR_PATH + \"X.npy\")\n",
    "    n_frames = np.shape(enr_x)[0]\n",
    "    enr_x = enr_x.reshape(n_frames, N_INP_FRMS * 60) # 60 MFCCs per frame\n",
    "    enr_y = np.load(ENR_PATH + \"y.npy\")\n",
    "    assert n_frames == np.shape(enr_y)[0]\n",
    "    print(\"Enroll X shape\", np.shape(enr_x))\n",
    "    print(\"Enroll y shape\", np.shape(enr_y))\n",
    "\n",
    "    # VERIFY DATA LOAD\n",
    "    ver_x = np.load(VER_PATH + \"X.npy\")\n",
    "    n_frames = np.shape(ver_x)[0]\n",
    "    ver_x = ver_x.reshape(n_frames, N_INP_FRMS * 60)\n",
    "    ver_y = np.load(VER_PATH + \"y.npy\")\n",
    "    assert n_frames == np.shape(ver_y)[0]\n",
    "    print(\"Verify X shape\", np.shape(ver_x))\n",
    "    print(\"Verify y shape\", np.shape(ver_y))\n",
    "\n",
    "    poss_spks = np.load(VER_PATH + \"y.npy\")\n",
    "\n",
    "    for curr_spk in set(poss_spks):\n",
    "        print(\"EVALUATING AND TRAINING FOR CURRENT SPEAKER:\", curr_spk)\n",
    "        model = get_ver_network_arch(MODEL_PATH)\n",
    "        tr_y = conv_to_ver_and_one_hot_encode(enr_y, curr_spk)\n",
    "        te_y = conv_to_ver_and_one_hot_encode(ver_y, curr_spk)\n",
    "        spk_path = MODEL_PATH + str(curr_spk) + \"/\"\n",
    "        mkdir(spk_path)\n",
    "        test_acc = train_and_test_network(model, enr_x, tr_y, ver_x, te_y, curr_spk, spk_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from svm_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in ivector data ./processed_data/ivectors_enroll_500_600/all-enroll-ivectors.ark\n",
      "number of distinct labels: 138\n",
      "number of features: 600\n",
      "number of ivectors: 13248\n",
      "i-vector matrix shape: (13248, 600)\n"
     ]
    }
   ],
   "source": [
    "def read_in_data():\n",
    "    enr_ivec_path = \"./processed_data/ivectors_enroll_500_600/all-enroll-ivectors.ark\"\n",
    "    (n_classes, n_features, n_ivectors, spk_labels, ivectors, utt_ids) = read_ivectors(enr_ivec_path)\n",
    "    return (n_classes, n_features, n_ivectors, spk_labels, ivectors, utt_ids)\n",
    "# (n_classes, n_features, n_ivectors, spk_labels, ivectors, utt_ids) = read_in_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import gauss\n",
    "from scipy.special import expit\n",
    "\n",
    "def gen_hashes(ivectors, n_features, n_hashes, n_bits_per_hash, hyperplane_ratio=0.85):\n",
    "    # Generate Cosine Hash hyperplants\n",
    "    #   N_HASH_BLOCKS = M = L = 1\n",
    "    #   Each Hash Fn: input = dimension n_features; output = # bits = dimension K = 10000\n",
    "    #   total number of hyperplanes to produce for cosine hashes: K*M\n",
    "    #   NOT implementing Moreno Lopez et al. (m choose 2) optimizations\n",
    "    assert np.shape(ivectors)[1] == n_features\n",
    "    print \"generating hashes with\",n_bits_per_hash,\"bits per hash\"\n",
    "    \n",
    "    n_hyperplanes = n_hashes*n_bits_per_hash\n",
    "    n_cos_hp = hyperplane_ratio*n_hyperplanes\n",
    "\n",
    "    hyperplanes = np.random.randn(n_features, n_hyperplanes)\n",
    "    cos_hashes = (np.sign(np.dot(ivectors, hyperplanes[:,:n_cos_hp])) + 1)/2.0\n",
    "    euc_hashes = np.floor(np.dot(ivectors, hyperplanes[:,n_cos_hp:]) % 2) # TODO CHANGE THIS BACK TO 2\n",
    "    print np.shape(cos_hashes), np.shape(euc_hashes)\n",
    "    hashes = (np.hstack((cos_hashes, euc_hashes))).astype(np.uint8)\n",
    "    return hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pyhashxx import hashxx\n",
    "\n",
    "def identity_post_hash_fn(x): return x\n",
    "def mod2_post_hash_fn(x): return x % 2\n",
    "\n",
    "def get_salts(dim):\n",
    "    return np.arange(dim) % 2\n",
    "\n",
    "def apply_salt_and_hash(hashes, salts, post_hash_fn):\n",
    "    nbph = np.shape(hashes)[1]\n",
    "    size = str(int(math.ceil(math.log(nbph, 2)))+1)\n",
    "    salted_str_hashes = (hashes + salts).astype('S'+size)\n",
    "    def hxx(x): return post_hash_fn(hashxx(x))\n",
    "    vect_hash_fn = np.vectorize(hxx)\n",
    "    return vect_hash_fn(salted_str_hashes)\n",
    "\n",
    "def apply_salt2_xor(hashes, salts):\n",
    "    return np.bitwise_xor(hashes, salts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_hamming_dists(X, vec):\n",
    "    return np.sum(np.abs(X - vec), axis=1)\n",
    "\n",
    "# n_cos_hyperplanes\n",
    "def compute_ind_hamming_dists(X, vec, n_cos):\n",
    "    hamming_dists = np.abs(X - vec)\n",
    "    return np.sum(hamming_dists[:,:n_cos], axis=1), np.sum(hamming_dists[:,n_cos:], axis=1)\n",
    "\n",
    "def get_top_n_guesses(hs_train, trn_labels, vec, n):\n",
    "    # written to get top 'n' guesses, but we do not need that right now\n",
    "    dists_to_vec = compute_hamming_dists(hs_train, vec)\n",
    "    top_spk_idxs = np.argsort(dists_to_vec)\n",
    "    top_guesses = [trn_labels[top_spk_idxs[i]] for i in range(n)]\n",
    "    top_dists = [dists_to_vec[top_spk_idxs[i]] for i in range(n)]\n",
    "    return top_guesses, top_guesses\n",
    "\n",
    "def get_top_guess(hs_train, trn_labels, vec):\n",
    "    # written to get top 'n' guesses, but we do not need that right now\n",
    "    n = 1\n",
    "    dists_to_vec = compute_hamming_dists(hs_train, vec)\n",
    "    top_spk_idx = np.argmin(dists_to_vec)\n",
    "    top_guess = trn_labels[top_spk_idx]\n",
    "    top_dist = dists_to_vec[top_spk_idx]\n",
    "    return top_guess, top_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def accuracy(n_correct, n_incorrect):\n",
    "    return n_correct/(n_correct + n_incorrect)\n",
    "\n",
    "def eval_approx_accuracy(hs_train, y_train, hs_test, y_test, stop_std_thres = 0.005, termination_window_size=200):\n",
    "    print 'evaluating accuracy with stop std thres', stop_std_thres, \", frame size\", termination_window_size\n",
    "    n_correct, n_incorrect = 0.0,0.0\n",
    "    accuracies = deque(range(termination_window_size))\n",
    "    for i in range(len(y_test)):\n",
    "        top_guess, top_dist = get_top_guess(hs_train, y_train, hs_test[i,])\n",
    "        accuracies.popleft()\n",
    "        if y_test[i] == top_guess:\n",
    "            n_correct += 1 \n",
    "        else:\n",
    "            n_incorrect += 1\n",
    "        acc = accuracy(n_correct, n_incorrect)\n",
    "        old_acc = accuracies.popleft()\n",
    "        if(np.std(accuracies) < stop_std_thres): break\n",
    "        else: accuracies.append(acc)\n",
    "    return acc, n_correct, n_incorrect\n",
    "\n",
    "def eval_accuracy(hs_train, y_train, hs_test, y_test):\n",
    "    print 'evaluating accuracy (full)'\n",
    "    n_correct, n_incorrect = 0.0,0.0\n",
    "    for i in range(len(y_test)):\n",
    "        top_guess, top_dist = get_top_guess(hs_train, y_train, hs_test[i,])\n",
    "        if y_test[i] == top_guess:\n",
    "            n_correct += 1 \n",
    "        else:\n",
    "            n_incorrect += 1\n",
    "    acc = accuracy(n_correct, n_incorrect)\n",
    "    return acc, n_correct, n_incorrect\n",
    "\n",
    "def plot_acc(nbphs, accs):\n",
    "    plt.clf()\n",
    "    fig = plt.figure()\n",
    "    plt.plot(nbphs, accs, '-o')\n",
    "    fig.suptitle('Accuracy as Function of LSH Size')\n",
    "    plt.xlabel('Total # Bits used in LSHs')\n",
    "    plt.ylabel('Test Set Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accs = []\n",
    "times = []\n",
    "import time\n",
    "\n",
    "def create_accuracy_per_nbphs_plot():\n",
    "    global accs\n",
    "    # values for number of bits per hash\n",
    "    nbphs = range(3000,8200,200)[::-1]\n",
    "\n",
    "    nbph = 8000\n",
    "    print \"testing num bits per hash:\", nbph\n",
    "    hashes = gen_hashes(ivectors, n_features, 1, nbph, hyperplane_ratio=0.9)\n",
    "    salts = get_salts(nbph)\n",
    "    new_hashes = apply_salt2_xor(hashes, salts)\n",
    "    hs_train, hs_test, y_train, y_test = train_test_split(new_hashes, spk_labels)\n",
    "    t0 = time.time()\n",
    "    acc, n_correct, n_incorrect = eval_accuracy(hs_train, y_train, hs_test, y_test)\n",
    "    times.append(time.time() - t0)\n",
    "    print \"got results:\", acc, n_correct, n_incorrect\n",
    "    accs.append(acc)\n",
    "    print \"\\n\"\n",
    "        \n",
    "    plot_acc(nbphs, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing num bits per hash: 8000\n",
      "generating hashes with 8000 bits per hash\n",
      "(13248, 7200) (13248, 800)\n",
      "Splitting into train and test. proportion:  0.1\n",
      "X train and test shapes (11923, 8000) (1325, 8000) y train and test shapes (11923,) (1325,)\n",
      "evaluating accuracy (full)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9a1edda19f40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_accuracy_per_nbphs_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-6376489f6305>\u001b[0m in \u001b[0;36mcreate_accuracy_per_nbphs_plot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mhs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_hashes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspk_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_incorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"got results:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_incorrect\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-43107d5891ab>\u001b[0m in \u001b[0;36meval_accuracy\u001b[1;34m(hs_train, y_train, hs_test, y_test)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mn_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_incorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtop_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_guess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtop_guess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mn_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9c000ebc484b>\u001b[0m in \u001b[0;36mget_top_guess\u001b[1;34m(hs_train, trn_labels, vec)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# written to get top 'n' guesses, but we do not need that right now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdists_to_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_hamming_dists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mtop_spk_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdists_to_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtop_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_spk_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9c000ebc484b>\u001b[0m in \u001b[0;36mcompute_hamming_dists\u001b[1;34m(X, vec)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_hamming_dists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# n_cos_hyperplanes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_ind_hamming_dists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create_accuracy_per_nbphs_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_dist_scores(hs_train, trn_labels, x, lbl, idx, nbph = 4000, num_spks = 50, save_dir = \"hash_dist_viz/\"):\n",
    "    cos, euc = compute_ind_hamming_dists(hs_train, x, nbph)\n",
    "    \n",
    "    guessed_spk = trn_labels[np.argmin(cos + euc)]\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    curr_spk = lbl\n",
    "    chosen_spks = set(random.sample(set(y_train), num_spks))\n",
    "    chosen_spks.add(curr_spk)\n",
    "\n",
    "    plot_data = {}\n",
    "    for chosen_spk in chosen_spks:\n",
    "        plot_data[chosen_spk] = [[],[]]\n",
    "\n",
    "    for i, spk in enumerate(y_train):\n",
    "        if spk in chosen_spks:\n",
    "            plot_data[spk][0].append(cos[i])\n",
    "            plot_data[spk][1].append(euc[i])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Dist Between a Test Vector LSH and Each Train Vector LSH (Black = Target Spk)')\n",
    "    plt.xlabel('Hamming Dist with Cosine LSH')\n",
    "    plt.ylabel('Hamming Dist with Euc LSH')\n",
    "\n",
    "    color_cycle=iter(cm.rainbow(np.linspace(0,1,len(chosen_spks)+1)))\n",
    "\n",
    "    for spk in chosen_spks:\n",
    "        nxt_color = 'k' if spk == curr_spk else next(color_cycle)\n",
    "        plt.scatter(plot_data[spk][0], plot_data[spk][1], color=nxt_color)\n",
    "\n",
    "    if guessed_spk == lbl:      \n",
    "        if(save_dir):\n",
    "            pylab.savefig(save_dir + str(idx) +\".png\",bbox_inches='tight')\n",
    "        else:\n",
    "            plt.show()\n",
    "    else:\n",
    "        if(save_dir):\n",
    "            pylab.savefig(save_dir + \"MISTAKE_\" + str(idx) +\".png\",bbox_inches='tight')\n",
    "        else:\n",
    "            print \"Mistake in classification!\"\n",
    "            plt.show()\n",
    "            \n",
    "def plot_all_dist_scores():\n",
    "    for idx in range(len(y_test)):\n",
    "        print \"On idx\", idx, \"of\", len(y_test)\n",
    "        plot_dist_scores(hs_train, y_train, hs_test[idx,:], y_test[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
